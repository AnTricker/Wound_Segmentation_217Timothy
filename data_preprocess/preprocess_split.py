import os
import re
import cv2
import numpy as np
import glob
import shutil
from tqdm import tqdm
from sklearn.model_selection import train_test_split


RAW_ROOT = "data/raw"
LABELED_ROOT = f"{RAW_ROOT}/labeled"
TEST_ROOT = f"{RAW_ROOT}/test"
OUT_ROOT = "data/processed"
TARGET_SIZE = (512, 512)
PREFIX_MAP = {
    "WoundSeg": "WS",
    "CO2Wound": "CO2"
}


def letterbox_resize(img, size, is_mask=False):

    # 1. å–å¾—åŸå§‹åœ–ç‰‡çš„ é«˜(ih) èˆ‡ å¯¬(iw)
    img_h, img_w = img.shape[:2]
    w, h = size
    
    # if the size match exactly, return the original image directly.
    if (int(img_h) == int(h)) and (int(img_w) == int(w)):
        return img
    
    # 2. è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹ (Scale)
    scale = min(w/img_w, h/img_h)
    
    # 3. è¨ˆç®—ç¸®æ”¾å¾Œçš„æ–°å°ºå¯¸ (nw, nh)
    new_w = int(img_w * scale)
    new_h = int(img_h * scale)
    
    # 4. æ±ºå®šç¸®æ”¾æ¼”ç®—æ³• (Interpolation)
    interpolation = cv2.INTER_NEAREST if is_mask else cv2.INTER_LINEAR
        
    # 5. åŸ·è¡Œç¸®æ”¾ (é€™æ™‚å€™é‚„æ²’æœ‰é»‘é‚Šï¼Œåªæ˜¯æŠŠåœ–è®Šå°äº†)
    resized_img = cv2.resize(img, (new_w, new_h), interpolation=interpolation)
    
    # 6. å»ºç«‹ç•«å¸ƒ (Canvas)
    # ç”¢ç”Ÿä¸€å¼µå…¨é»‘ (0) çš„ 512x512 åº•åœ–
    if len(img.shape) == 3:
        # å½©è‰²åœ–: (512, 512, 3)
        new_img = np.zeros((h, w, 3), np.uint8)
    else:
        # ç°éšåœ–/Mask: (512, 512)
        new_img = np.zeros((h, w), dtype=np.uint8)
    
    # 7. è¨ˆç®—è²¼åœ–ä½ç½® (Centering)
    # æˆ‘å€‘è¦æŠŠç¸®å°å¾Œçš„åœ–ã€Œç½®ä¸­ã€è²¼åœ¨é»‘ç•«å¸ƒä¸Š
    dx = (w-new_w) // 2
    dy = (h-new_h) // 2
    
    # 8. è²¼ä¸Šå» (Paste)
    if len(img.shape) == 3:
        new_img[dy:dy+new_h, dx:dx+new_w, :] = resized_img
    else:
        new_img[dy:dy+new_h, dx:dx+new_w] = resized_img
        
    return new_img


def generate_new_name(original_fname, dataset_name):
    """
    è¼¸å…¥: IMG435.png, CO2Wound
    è¼¸å‡º: CO2_435.png
    """
    base_name, _ = os.path.splitext(original_fname)
    prefix = PREFIX_MAP.get(dataset_name, dataset_name)
    
    # ä½¿ç”¨ Regex æ‰¾å‡ºæª”åä¸­çš„æ‰€æœ‰æ•¸å­—åºåˆ—
    numbers = re.findall(r'\d+', base_name)
    
    if numbers:
        # é€šå¸¸ ID æ˜¯æª”åä¸­æœ€å¾Œä¸€çµ„æ•¸å­— (é¿å…æŠ“åˆ°æ—¥æœŸ)
        # ä¾‹å¦‚: IMG_20251212_005.jpg -> å– 005
        real_id = numbers[-1]
    else:
        # å¦‚æœæª”åå®Œå…¨æ²’æ•¸å­— (ä¾‹å¦‚ image.png)ï¼Œå°±ä¿ç•™åŸå
        real_id = base_name
        
    return f"{prefix}_{real_id}.png"


def process_folder(dataset_name, subset_type, input_img_dir, input_mask_dir):
    
    if not os.path.exists(input_img_dir):
        print(f"   âš ï¸ Path not found: {input_img_dir}")
        return []
    
    # 1. æœå°‹åœ–ç‰‡
    extension = ['*.jpg', '*.jpeg', '*.png', '*.bmp']
    img_paths = []
    for ext in extension:
        img_paths.extend(glob.glob(os.path.join(input_img_dir, ext)))
        img_paths.extend(glob.glob(os.path.join(input_img_dir, ext.upper())))

    img_paths = sorted(list(set(img_paths))) # å»é™¤é‡è¤‡ä¸¦æ’åº
    processed_data = []
    
    if not img_paths:
        print(f"   âš ï¸ No images found in {dataset_name}/{subset_type}")
        return []
    
    for img_path in tqdm(img_paths, desc=f"Processing: {dataset_name}"):
        fname = os.path.basename(img_path)
        basename, _ = os.path.splitext(fname)

        candidate = [
            os.path.join(input_mask_dir, fname),                  # 1. å®Œå…¨åŒå (image.jpg å° image.jpg)
            os.path.join(input_mask_dir, basename + ".png"),      # 2. åŒåä½†å‰¯æª”åæ˜¯ png (å¸¸è¦‹ï¼šåœ–ç‰‡æœ‰å£“ç¸®ï¼ŒMask ç„¡å£“ç¸®)
            os.path.join(input_mask_dir, basename + ".jpg")       # 3. åŒåä½†å‰¯æª”åæ˜¯ jpg
        ]
        
        mask_path = None
        for c in candidate:
            if os.path.exists(c):
                mask_path = c
                break
        
        if subset_type == 'labeled' and mask_path is None:
            continue
        
        img = cv2.imread(img_path)
        if img is None: continue
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # ä¸ç®¡åŸæœ¬ Mask æ˜¯ RGB å½©è‰²é‚„æ˜¯ç°éšï¼Œé€™è£¡é€šé€šè®Šæˆå–®å±¤ç°éšã€‚
        # ä¸ç®¡åŸæœ¬ Mask æ˜¯ 0/1 (å…¨é»‘) é‚„æ˜¯ 0/255 (é»‘ç™½)ï¼Œé€™è£¡é€šé€šè®Šæˆ 0/255ã€‚
        # çµæœï¼šæ‰€æœ‰çš„ Mask è®Šæˆäº†çµ±ä¸€è¦æ ¼ï¼Œä¸”è‚‰çœ¼å¯è¦‹ï¼ˆç™½è‰²çš„å‚·å£ï¼‰
        mask = None
        if mask_path is not None:
            mask_raw = cv2.imread(mask_path)
            
            if mask_raw is not None:
                if len(mask_raw.shape) == 3:
                    mask = cv2.cvtColor(mask_raw, cv2.COLOR_BGR2GRAY)
                else:
                    mask = mask_raw
                
                mask = mask.astype(np.float32)
                if mask.max() > 1.0:
                    mask /= 255.0
                
                mask[mask >= 0.5] = 255
                mask[mask < 0.5] = 0
                mask = mask.astype(np.uint8)
        
        img_lb = letterbox_resize(img, TARGET_SIZE)
        if mask is not None:
            mask_lb = letterbox_resize(mask, TARGET_SIZE, True)
        else:
            # å¦‚æœæ˜¯ Test set ä¸”æ²’æœ‰ Maskï¼Œè‡ªå‹•ç”Ÿæˆä¸€å¼µå…¨é»‘åœ–ç•¶ä½œã€Œæ›¿èº«ã€
            # é€™æ¨£ç¨‹å¼æ‰ä¸æœƒå› ç‚ºè®Šæ•¸æ˜¯ None è€Œå ±éŒ¯
            mask_lb = np.zeros((TARGET_SIZE[1], TARGET_SIZE[0]), dtype=np.uint8)
        
        new_filename = generate_new_name(fname, dataset_name)
        processed_data.append({
            "name": new_filename,
            "img": img_lb,
            "mask": mask_lb
        })
    
    return processed_data

def save_data(data_list, out_dir):
    
    os.makedirs(os.path.join(out_dir, "images"), exist_ok=True)
    os.makedirs(os.path.join(out_dir, "masks"), exist_ok=True)
    
    names = []
    for item in data_list:
        name = item['name']
        cv2.imwrite(os.path.join(out_dir, "images", name), cv2.cvtColor(item['img'], cv2.COLOR_RGB2BGR))
        cv2.imwrite(os.path.join(out_dir, "masks", name), item['mask'])
        names.append(name)
    return names


def main():
    
    if os.path.exists(OUT_ROOT):
        print(f"ğŸ—‘ï¸  Cleaning up old data at: {OUT_ROOT} ...")
        shutil.rmtree(OUT_ROOT, ignore_errors=True) # éè¿´åˆªé™¤æ•´å€‹è³‡æ–™å¤¾
    
    datasets = ["WoundSeg", "CO2Wound"]
    print(f"[INFO] Raw Root: {RAW_ROOT}")
    print(f"[INFO] Labeled Root: {LABELED_ROOT}")
    print(f"[INFO] Test Root: {TEST_ROOT}")
    
    for ds_name in datasets:
        print(f"\nğŸš€ Pipeline: {ds_name} (Prefix: {PREFIX_MAP.get(ds_name)})")
        
        labeled_img = os.path.join(LABELED_ROOT, ds_name, "images")
        labeled_mask = os.path.join(LABELED_ROOT, ds_name, "masks")
        test_img = os.path.join(TEST_ROOT, ds_name)
        test_mask = os.path.join(TEST_ROOT, ds_name, "masks")
        
        # æˆå“å€
        out_base = os.path.join(OUT_ROOT, ds_name)
        os.makedirs(out_base, exist_ok=True)
        
        # ç´€éŒ„å€ (Splits - å­˜æ”¾ txt çš„åœ°æ–¹)
        split_dir = os.path.join(OUT_ROOT, "splits", ds_name)
        os.makedirs(split_dir, exist_ok=True)
        
        # 1. å‘¼å«ç”Ÿç”¢ç·š (process_folder)
        # é€™æ™‚å€™ï¼Œæ‰€æœ‰çš„åœ–ç‰‡éƒ½å·²ç¶“åœ¨è¨˜æ†¶é«”è®Šæˆ 512x512 ä¸”æ”¹å¥½åå­—äº†
        print("  -> Processing Labeled set...")
        data = process_folder(ds_name, "labeled", labeled_img, labeled_mask)
        
        if len(data) > 0:
            # 2. é»ƒé‡‘æ¯”ä¾‹åˆ‡åˆ† (Train/Val Split)
            #run4 æ”¹æˆ Train/Val 8:2
            # test_size=0.2 ä»£è¡¨åˆ‡å‡º 20% çµ¦é©—è­‰é›† (Val)ï¼Œå‰©ä¸‹ 80% çµ¦è¨“ç·´é›† (Train)
            # random_state=42 ç¢ºä¿æ¯æ¬¡åˆ‡å‡ºä¾†çš„çµæœéƒ½ä¸€æ¨£
            train, val = train_test_split(data, test_size=0.22, random_state=42)
            
            # 3. å¯¦éš›å­˜æª” (æŠŠè¨˜æ†¶é«”å¯«å…¥ç¡¬ç¢Ÿ)
            # é€™æ™‚å€™æ‰æœƒç”¢ç”Ÿ data/processed/WoundSeg/train/images/WS_001.png
            t_names = save_data(train, os.path.join(out_base, "train"))
            v_names = save_data(val, os.path.join(out_base, "val"))
            
            # 4. å¯«å…¥é»åç°¿ (.txt)
            # é€™äº› txt æª”æ¡ˆå°±æ˜¯ä»¥å¾Œ Dataset Loader è®€å–çš„ä¾æ“š
            with open(os.path.join(split_dir, "train.txt"), "w") as f: 
                f.write("\n".join(t_names))
            with open(os.path.join(split_dir, "val.txt"), "w") as f: 
                f.write("\n".join(v_names))
                
            print(f"     âœ… Train: {len(t_names)} | Val: {len(v_names)}")
        
        # 1. å‘¼å«ç”Ÿç”¢ç·š (process_folder)
        print("  -> Processing Test set...")
        t_data = process_folder(ds_name, "test", test_img, test_mask)
        
        if len(t_data) > 0:
            # 2. æ¸¬è©¦é›†ä¸éœ€è¦åˆ‡åˆ†ï¼Œç›´æ¥å…¨å­˜ï¼
            test_names = save_data(t_data, os.path.join(out_base, "test"))
            
            # 3. å¯«å…¥ test.txt
            with open(os.path.join(split_dir, "test.txt"), "w") as f: 
                f.write("\n".join(test_names))
                
            print(f"     âœ… Test: {len(test_names)}")


if __name__ == "__main__":
    main()