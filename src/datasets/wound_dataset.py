import os
import cv2
import torch
import numpy as np
from torch.utils.data import Dataset

class SegmentationDataset(Dataset):
    
    def __init__(
        self, 
        root_dir: str, 
        datasets, 
        split="train",
        transform=None
    ):
        """
        é€šç”¨åˆ†å‰²è³‡æ–™é›†
        Args:
            root_dir (str): 'data/processed'
            datasets (list): è³‡æ–™é›†åç¨±åˆ—è¡¨ï¼Œä¾‹å¦‚ ['WoundSeg', 'CO2Wound']
            split (str): 'train', 'val', æˆ– 'test'
            transform (albumentations): è³‡æ–™å¢žå¼·ç‰©ä»¶
        """
        
        self.root_dir = root_dir
        self.transform = transform
        self.files = [] # é€™æ˜¯å­˜æ”¾æ‰€æœ‰æª”æ¡ˆè·¯å¾‘çš„å¤§æ¸…å–®
        
        for ds in datasets:
            # 1. è®€å– preprocess ç”Ÿæˆçš„ txt æ¸…å–®
            # è·¯å¾‘ç¯„ä¾‹: data/processed/splits/WoundSeg/train.txt
            split_file = os.path.join(self.root_dir, "splits", ds, f"{split}.txt")
            
            if not os.path.exists(split_file):
                print(f"[Warn] Split file not found: {split_file} (Skipping {ds})")
                continue
            
            with open(split_file, "r") as f:
                fnames = [line.strip() for line in f.readlines()]
            
            # 2. çµ„åˆå®Œæ•´è·¯å¾‘
            # è³‡æ–™å¯¦éš›ä½ç½®: data/processed/WoundSeg/train/images/WS_001.png
            base_path = os.path.join(self.root_dir, ds, split)
            for fname in fnames:
                img_path = os.path.join(base_path, fname, "images")
                mask_path = os.path.join(base_path, fname, "masks")
                self.files.append((img_path, mask_path))
    
    
    def __len__(self):
        return len(self.files)
    
    
    def __getitem__(self, idx):
        
        # 1. æ‹¿è·¯å¾‘
        img_path, mask_path = self.files[idx]
        
        # 2. è®€åœ–ç‰‡ (è½‰ RGB)
        img = cv2.imread(img_path)
        # ðŸ”¥ [é™¤éŒ¯é—œéµ] æª¢æŸ¥æ˜¯å¦è®€å–å¤±æ•—
        if img is None:
            raise FileNotFoundError(f"âŒ ç„¡æ³•è®€å–åœ–ç‰‡ï¼Œè«‹æª¢æŸ¥è·¯å¾‘æ˜¯å¦å­˜åœ¨: {img_path}")
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # 3. è®€ Mask (è½‰å–®å±¤ç°éšŽ)
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            raise RuntimeError(f"Failed to read mask: {mask_path}")
        
        # 4. ðŸ”¥ Data Augmentation (åœ¨é€™è£¡åš!)
        # æˆ‘å€‘ä½¿ç”¨ albumentationsï¼Œå®ƒæœƒåŒæ™‚è™•ç† image å’Œ mask
        if self.transform is not None:
            augmented = self.transform(image=img, mask=mask)
            img = augmented["image"]
            mask = augmented["mask"]
        
        # 5. è½‰ Tensor èˆ‡æ¨™æº–åŒ– (Normalization)
        # åœ–ç‰‡: 0-255 -> 0.0-1.0 (float32)
        # Mask: 0-255 -> 0.0-1.0 (float32)
        # å¦‚æžœ transform è£¡æ²’æœ‰ ToTensorV2ï¼Œæˆ‘å€‘æ‰‹å‹•è½‰
        if isinstance(img, np.ndarray):
            img = img.astype(np.float32) / 255.0
            img = np.transpose(img, (2, 0, 1)) # (H, W, 3) -> (3, H, W)
            img = torch.from_numpy(img)
        if isinstance(mask, np.ndarray):
            mask = mask.astype(np.float32) / 255.0
            mask[mask >= 0.5] = 1
            mask[mask < 0.5] = 0
            mask = np.expand_dims(mask, axis=0) # (H, W) -> (1, H, W) (å¢žåŠ  Channel ç¶­åº¦)
            mask = torch.from_numpy(mask)

        return img, mask