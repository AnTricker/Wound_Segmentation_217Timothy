import sys
import os
import torch
import torch.nn as nn
from PIL import Image
from torchvision import transforms
from torchvision.utils import save_image
from typing import Tuple, List, cast

# --- è·¯å¾‘è¨­å®š ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from models.unet import UNet

# æ”¯æ´çš„åœ–ç‰‡æ ¼å¼
VALID_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.bmp'}


def load_and_preprocess(image_path: str, device: torch.device, target_size: Tuple[int, int] = (512, 512)) -> torch.Tensor:
    """
    è®€å–ä¸¦é è™•ç†åœ–ç‰‡ã€‚
    Args:
        image_path (str): åœ–ç‰‡è·¯å¾‘
        device (torch.device): è£ç½®
        target_size (Tuple[int, int]): Resize å¤§å°
    Returns:
        torch.Tensor: (1, 3, H, W)
    """
    # 1. è®€å–åœ–ç‰‡
    pil_image = Image.open(image_path).convert("RGB")
    
    # 2. å®šç¾©è½‰æ›
    transform_pipeline = transforms.Compose([
        transforms.Resize(target_size),
        transforms.ToTensor(),
    ])
    
    # 3. åŸ·è¡Œè½‰æ› (é€™è£¡æ‹¿æ‰äº† : torch.Tensor çš„å¼·åˆ¶å®£å‘Šï¼Œè®“ Python è‡ªå‹•æ¨æ–·)
    img_tensor = cast(torch.Tensor, transform_pipeline(pil_image))
    
    # 4. å¢åŠ  Batch ç¶­åº¦ä¸¦ç§»è‡³ Device
    # Pylance å¯èƒ½æœƒåœ¨é€™è£¡æç¤º img_tensor å‹åˆ¥ä¸æ˜ï¼Œä½†åŸ·è¡Œæ™‚é€™æ˜¯ 100% æ­£ç¢ºçš„
    return img_tensor.unsqueeze(0).to(device)


def process_single_image(model: nn.Module, image_path: str, output_path: str, device: torch.device) -> None:
    """
    å°å–®å¼µåœ–ç‰‡é€²è¡Œæ¨è«–ä¸¦å­˜æª”ã€‚
    Args:
        model (nn.Module): æ¨¡å‹
        image_path (str): è¼¸å…¥åœ–ç‰‡è·¯å¾‘
        output_path (str): è¼¸å‡ºçµæœè·¯å¾‘
        device (torch.device): è£ç½®
    """
    # 1. Preprocess
    input_tensor = load_and_preprocess(image_path, device, target_size=(512, 512))
    
    # 2. Inference
    model.eval()
    with torch.no_grad():
        logits = model(input_tensor)
        probs = torch.sigmoid(logits)
        mask = (probs > 0.5).float()
        
    # 3. Save (Cat Input + Pred)
    mask_rgb = mask.repeat(1, 3, 1, 1)
    combined = torch.cat([input_tensor, mask_rgb], dim=3)
    
    save_image(combined, output_path)
    print(f"âœ… Saved: {os.path.basename(output_path)}")


def process_folder(model: nn.Module, input_dir: str, output_dir: str, device: torch.device) -> None:
    """
    éæ­·æ•´å€‹è³‡æ–™å¤¾é€²è¡Œæ¨è«–ã€‚
    Args:
        model (nn.Module): æ¨¡å‹
        input_dir (str): è¼¸å…¥è³‡æ–™å¤¾è·¯å¾‘
        output_dir (str): è¼¸å‡ºè³‡æ–™å¤¾è·¯å¾‘
        device (torch.device): è£ç½®
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # å–å¾—æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆ
    files = [f for f in os.listdir(input_dir) if os.path.splitext(f)[1].lower() in VALID_EXTENSIONS]
    
    print(f"ğŸ“‚ Found {len(files)} images in {input_dir}")
    
    for filename in files:
        img_path = os.path.join(input_dir, filename)
        out_path = os.path.join(output_dir, filename)
        
        process_single_image(model, img_path, out_path, device)


def main() -> None:
    # --- 1. è¨­å®š ---
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    run_name = "unet_v1"
    
    ckpt_path = os.path.join(project_root, f"outputs/checkpoints/{run_name}/best.pt")
    
    # è¼¸å…¥è³‡æ–™å¤¾ (WoundSeg)
    input_folder_name = "WoundSeg" 
    input_root_dir = os.path.join(project_root, "data/raw/inference_only", input_folder_name)
    
    # è¼¸å‡ºè³‡æ–™å¤¾
    output_root_dir = os.path.join(project_root, f"outputs/inference/{run_name}", input_folder_name)
    
    # --- 2. è¼‰å…¥æ¨¡å‹ ---
    print(f"Using Device: {device}")
    model = UNet(in_channels=3, out_channels=1).to(device)
    
    if not os.path.exists(ckpt_path):
        print(f"âŒ Checkpoint not found: {ckpt_path}")
        return
    
    checkpoint = torch.load(ckpt_path, map_location=device)
    state = checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint
    model.load_state_dict(state)
    print("âœ… Model loaded successfully.")
    
    # --- 3. åŸ·è¡Œè³‡æ–™å¤¾æ¨è«– ---
    if os.path.exists(input_root_dir):
        process_folder(model, input_root_dir, output_root_dir, device)
        print(f"\nğŸ‰ All Done! Results saved to: {output_root_dir}")
    else:
        print(f"âŒ Input folder not found: {input_root_dir}")


if __name__ == "__main__":
    main()